{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get download links for h5ad files from HuBMAP and SenNet (HRApop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hra_pop_version = 'v0.11.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and extract Entity IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_full = pd.read_csv(\n",
    "    f'https://raw.githubusercontent.com/x-atlas-consortia/hra-pop/refs/heads/main/output-data/{hra_pop_version}/reports/universe-ad-hoc/sankey.csv')\n",
    "\n",
    "sankey_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter, only keep sc-transcriptomics data that was run through at least one cell type annotation tool\n",
    "sankey = sankey_full[((sankey_full['cell_type_annotation_tool']).notna()) & (sankey_full['cell_type_annotation_tool'] != 'sc_proteomics')]\n",
    "sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract UUIDs\n",
    "# https://entity.api.hubmapconsortium.org/entities/ebaa609a1819b22767471082d7baa0d9\n",
    "\n",
    "def get_uuids(column:pd.core.series.Series, effort:str):\n",
    "  \"\"\"Gets UUIDs from dataset IDs\n",
    "\n",
    "  Args:\n",
    "      column (pd.core.series.Series): a Pandas series\n",
    "      effort (str): effort name\n",
    "\n",
    "  Returns:\n",
    "      result: list with UUIDs\n",
    "  \"\"\"\n",
    "  result = set(dataset_id.split('/')[len(dataset_id.split('/'))-1]\n",
    "            for dataset_id in column if effort in dataset_id)\n",
    "  return result\n",
    "\n",
    "\n",
    "hubmap_ids = get_uuids(sankey['dataset_id'], 'hubmap')\n",
    "sennet_ids = get_uuids(sankey['dataset_id'], 'sennet')\n",
    "print(f'hubmap_ids: {len(hubmap_ids)}, sennet_ids: {len(sennet_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build URLs for download, export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_api_hubmap = 'https://assets.hubmapconsortium.org/'\n",
    "assets_api_sennet = 'https://assets.api.sennetconsortium.org/'\n",
    "filename = 'expr.h5ad'\n",
    "\n",
    "result = {\n",
    "  'effort':[],\n",
    "  'uuid': [],\n",
    "  'download_url':[]\n",
    "}\n",
    "\n",
    "def assemble_url(ids:list, url:str, effort:str):\n",
    "  for id in ids:\n",
    "    result['effort'].append(effort)\n",
    "    result['uuid'].append(id)\n",
    "    result['download_url'].append(f'{url}{id}/{filename}')  \n",
    "    \n",
    "assemble_url(hubmap_ids, assets_api_hubmap, 'hubmap')\n",
    "assemble_url(sennet_ids, assets_api_sennet, 'sennet')\n",
    "\n",
    "df_result = pd.DataFrame(result)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_result.to_csv('download_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download h5ad files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the data folder is present\n",
    "folder_path = \"data\"\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder '{folder_path}' created.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path}' already exists.\")\n",
    "\n",
    "def download_h5ad(uuid:str, url:str):\n",
    "  \"\"\"Downloads h5ad files given download URL and UUID\n",
    "\n",
    "  Args:\n",
    "      uuid (str): UUID\n",
    "      url (str): download URL\n",
    "  \"\"\"\n",
    "  # Define the path to the file. \n",
    "  file_path = f'{folder_path}/{uuid}.h5ad'\n",
    "\n",
    "    # Check if the file exists\n",
    "  if not os.path.exists(file_path):\n",
    "      # If the file doesn't exist, run the curl command\n",
    "      !curl -L {url} -o {file_path}\n",
    "      print(f\"File downloaded and saved at {file_path}\")\n",
    "  else:\n",
    "      print(f\"File already exists at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through df and download if needed\n",
    "for uuid, download_url in zip(df_result['uuid'], df_result['download_url']):\n",
    "  print(f'Attempting to download: {download_url}')\n",
    "  download_h5ad(uuid, download_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
